{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBju6qwE_w-f"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLRn9m2s_zUu"
   },
   "source": [
    "I have two dataset of rooten and fresh banana  \n",
    "First google drive is mounted to access the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29358,
     "status": "ok",
     "timestamp": 1732322542810,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "R7YEYC1p_7nt",
    "outputId": "e98289da-23b5-470d-ffad-eda404552560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cukcl8DETAi0"
   },
   "source": [
    "I got into this habit of inserting all the imports code in single code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9645,
     "status": "ok",
     "timestamp": 1732322558110,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "0b71uBfBQffE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDB5IZwXdws5"
   },
   "source": [
    "lets get the gpu needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1732322632956,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "7navQiL9dzFF",
    "outputId": "e1623ce7-b7e2-48cc-fd1a-4a2292a82e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_8sjXNrwjY6"
   },
   "source": [
    "Now i save the path to the data in two variables  \n",
    "I will retrive data in the drive via these links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GPU (NVIDIA GeForce GTX 1650)\n",
      "Total GPU Memory: 4.29 GB\n",
      "CUDA Capability: 7.5\n",
      "PyTorch Version: 2.3.1+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Device: GPU ({gpu_name})\")\n",
    "    print(f\"Total GPU Memory: {total_memory:.2f} GB\")\n",
    "    print(f\"CUDA Capability: {torch.cuda.get_device_properties(0).major}.{torch.cuda.get_device_properties(0).minor}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Device: CPU\")\n",
    "    \n",
    "# PyTorch version\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Selected device\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1732322643825,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "oDwOEmY7uv6J"
   },
   "outputs": [],
   "source": [
    "#Path to folders with data in drive\n",
    "F_Banana = r\"C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\F_Banana\"\n",
    "S_Banana = r\"C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\S_Banana\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TNkAQpOw1d7"
   },
   "source": [
    "This code snippet retrives data from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "executionInfo": {
     "elapsed": 3602,
     "status": "ok",
     "timestamp": 1732322650228,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "79Go3JMcuzra",
    "outputId": "4e9a6ba1-f2cb-43d0-f411-54a7bd15decd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=64x64 at 0x1948BA7BB50>\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD0jxH40tvDk1vbyxM8kylwcjAA49R3xWZH8UrL/nkR9R9fQ/T9a4z4vSf8T3T1Ha2J/wDHjXDQy5A5qIQTjcTk1Kx73B8TNMkYblIBI7N6/T0rQi8faK45uAp9CG9vb6/lXgtu/I+ta0BGRT5bbDvc9pXxvpLn5ZQfxx6+3t+tWj4r0tQN06gltv3hXktoyoADjrmrDSjzc4XrnpRdjPVB4o0rbuNygHruH+PvU8OvabO6rHdRkscD5hXj1/q1tYWhedlVOmMZz+FVfOG5WUDBIIIFON2J6EPxbdT4ptVZsKtqMn/gTVw0LYOO4rrPi07nxYAOdtsn5ZNcTBKTKpY4DDg0oO0Vclxu3Y3LZ+RWtBJjFYUDbT1B+laMUucVd00CTRuxS471I0/cms2KXAFVNQ1ExLsi5kPH0rNuxok3oiHxDm+aKNWykZJb6nitmMGOKOM9VAB/CsbTommmWD7zOwaQ/j0/OtmSXfcMR3Ymii3J3YVoqKsVvii2/wAaSj+7BGP0z/WuO0vT31S6MCSbHiHy5OBjP/1zXVfEh9/ji9/2VjH/AI4K4mZZYZRNEzKfVTihxk6dluTCSU9ToDpslvcNFdu0ZTrIi5X2+lXobKU+W6TRSKxx8vWrOieK7K9hFtf7YpzH5bM/RxjHWukh0jRrqFB9mhCIoAdGIP4kda8yVepB2mrM9CMISWmpkS6LIqFXvoIDjOXbtVS20drx2is0NztBLTEYUV2NtB4YsyALe0eRRz5sm4j8CahvfGNpGBBpUSMwPPybUH4U6cp1HZXY5ckF2MgaU+i2CFvlnnOR6hR3qkB8wPvVm8vpb2UzTyF3bv6ewqtuG4e9etSi4rU82rLmZl+PnD+N9SIOcOo/JRXPDBGCMitXxfNv8W6o+f8Al4YflxWIH561cF7qMm9WNltM8r09KWI3sSlI5JAh4K54NSLJxUiycZzTcU90NTaJII7g/fmZV7gHGfyrWtXWFdq8VlpKcmphKcZFPlQc7ZurNuHWnq+XH1rKgnJ4Jq/C2XU00iWz/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.jpg\n"
     ]
    }
   ],
   "source": [
    "file_list =os.listdir(F_Banana) #file names in F-Banana are listed in file_list\n",
    "file_name=file_list[0]\n",
    "image_path=os.path.join(F_Banana, file_name)#full path to a particular file\n",
    "image = Image.open(image_path).convert('RGB')  # Converting to RGB\n",
    "image = image.resize((64, 64))#resizing the image\n",
    "print(image)\n",
    "display(image)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5nhOR-KCxo0"
   },
   "source": [
    "So lets give a brief idea of whats been done till now an what things will be done in the future.\n",
    "\n",
    "**Tillnow** we have able to retrive data from the drive link\n",
    "we have a list of links of data which can be later used for training pupose\n",
    "\n",
    "**Whats ahead?**\n",
    "We need to design a dataloader which will load data onto the model\n",
    "We need to make a model\n",
    "Then use the model to predict the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15204,
     "status": "ok",
     "timestamp": 1732322668822,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "Wum-C_yyPRaY",
    "outputId": "fcf562f1-121b-4557-b829-62e8136860c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images: torch.Size([32, 3, 224, 224])\n",
      "Batch of labels: tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Define labels\n",
    "labels = {'fresh': 0, 'rotten': 1}\n",
    "\n",
    "# Load images and assign labels\n",
    "data = []\n",
    "for label, folder in [('fresh', F_Banana), ('rotten', S_Banana)]:\n",
    "    for file_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, file_name)\n",
    "        if file_name.endswith(('.jpg', '.png', '.jpeg')):  # Filter image files\n",
    "            data.append((img_path, labels[label]))\n",
    "\n",
    "# Split into train and test datasets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to a standard size\n",
    "    transforms.ToTensor(),         # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class BananaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BananaDataset(train_data, transform=transform)\n",
    "test_dataset = BananaDataset(test_data, transform=transform)\n",
    "\n",
    "# Convert to DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example: Checking one batch\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch of images: {images.shape}\")  # Should be [batch_size, 3, 224, 224]\n",
    "    print(f\"Batch of labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1732322674186,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "PCb8AxTAE7ff",
    "outputId": "2c95b7c6-8444-404a-caf2-b268566c8a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.BananaDataset object at 0x000001948BC4A510>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1732322677784,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "3d0m_wHNQzHX",
    "outputId": "272d70fb-6eee-4e14-9c90-1f3823f88e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 1600 data for training and 400 for testing\n"
     ]
    }
   ],
   "source": [
    "print(f\"we have {len(train_data)} data for training and {len(test_data)} for testing\")\n",
    "#we have a huge dataset and we cant inset it directly into the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlJW9KZKTc4D"
   },
   "source": [
    "its an matrics of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6677,
     "status": "ok",
     "timestamp": 1732322758203,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "Ym9q-Gr_Thl-",
    "outputId": "8d748a68-836f-470a-ff37-be282c7c3987"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "# Freeze earlier layers (optional, depending on dataset size)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1732322802952,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "Q8ZRy8jaT1nA"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epoch=10\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1732322928807,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "IlyJkza3VWV6"
   },
   "outputs": [],
   "source": [
    "#so we have build up all of our arsenal required for the final job of training our small model and test how well it did its job\n",
    "#now lets train our model\n",
    "#here we define the tarining_looop which takes dataloader which feeds data in batches, training_loop further takes model itself, loss function and optimizer.\n",
    "#the sole purpose here is to calculate the loss using loss_fn on the ouput of the model when inputed with dataloader input and optimize model parameter using the optimizer specified in the argument\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "      #let us first load the data into the device conatining model\n",
    "        X, y = X.to(device), y.to(device)\n",
    "      #In this loop batch hold the batch value given by dataloader and X and y values yet again from dataloader\n",
    "      #X dosent hold a single image rather it holds batch of images\n",
    "      #We loop through every batch of image\n",
    "      #And perform following computation, every batch\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        #Output of batch of images\n",
    "        loss = loss_fn(pred, y)\n",
    "        #single loss value if computed from the batch of output\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        #we propgate the loss back to each layers for gradient computation\n",
    "        optimizer.step()\n",
    "        #Then we optimize the model parameter\n",
    "        optimizer.zero_grad()\n",
    "        #Everytime we backpropagate, gradients value gets stored for optimization purposes, but if not set to zero the gradient of next batch will be accumulated\n",
    "        #now if you want to optimize the model after every 5 batches of data then do zero-grad after every 5 batches, till then the gradient of each of those 5 batches will be accumulated\n",
    "        #but for now we want to optimize the model after each batch so we need to zero-grad after every batch\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(batch)\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # No gradients are required during evaluation\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            all_preds.append(pred.argmax(1).cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Concatenate all predictions and labels\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    test_loss /= num_batches\n",
    "    accuracy = correct / size\n",
    "    precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * accuracy):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "    print(f\"Precision: {precision:>0.2f}, Recall: {recall:>0.2f}, F1-Score: {f1:>0.2f}\")\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 11177538\n"
     ]
    }
   ],
   "source": [
    "# Calculate total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214626,
     "status": "ok",
     "timestamp": 1732323146444,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "74ftuyUyVo6k",
    "outputId": "0983b843-840a-46bc-8466-fdc64706cdf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.713898  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.433797\n",
      "Precision: 0.90, Recall: 0.90, F1-Score: 0.90\n",
      "Confusion Matrix:\n",
      " [[191   8]\n",
      " [ 33 168]]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.444314  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.326903\n",
      "Precision: 0.96, Recall: 0.96, F1-Score: 0.96\n",
      "Confusion Matrix:\n",
      " [[194   5]\n",
      " [ 11 190]]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.343725  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.263088\n",
      "Precision: 0.98, Recall: 0.98, F1-Score: 0.98\n",
      "Confusion Matrix:\n",
      " [[196   3]\n",
      " [  4 197]]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.275994  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.229681\n",
      "Precision: 0.99, Recall: 0.98, F1-Score: 0.98\n",
      "Confusion Matrix:\n",
      " [[197   2]\n",
      " [  4 197]]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.319953  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.192514\n",
      "Precision: 0.99, Recall: 0.99, F1-Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[198   1]\n",
      " [  1 200]]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.210448  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.172126\n",
      "Precision: 0.99, Recall: 0.99, F1-Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[198   1]\n",
      " [  2 199]]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.173026  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.152624\n",
      "Precision: 0.99, Recall: 0.99, F1-Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[198   1]\n",
      " [  2 199]]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.145969  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.140410\n",
      "Precision: 0.99, Recall: 0.99, F1-Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[198   1]\n",
      " [  1 200]]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.113789  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.129370\n",
      "Precision: 0.99, Recall: 0.99, F1-Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[198   1]\n",
      " [  1 200]]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.137972  [   32/ 1600]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.118284\n",
      "Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n",
      "Confusion Matrix:\n",
      " [[198   1]\n",
      " [  0 201]]\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "#now all we need to do is train and test the model for the number of times(epochs) we want\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17096,
     "status": "ok",
     "timestamp": 1732323445780,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "kqDIkBePg_8k",
    "outputId": "4263014a-d268-4d23-e625-3caefa5305d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\resnet_model_parameters.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = r\"C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\resnet_model_parameters.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model parameters saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LW1iSHDbbPpA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=150528, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly loading the model parameters if you have already trained the model\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\model_parameters.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode (important for inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value of the image is: 0\n",
      "Actual label of the image is: 0\n",
      "Predicted value of the image is: 1\n",
      "Actual label of the image is: 1\n",
      "Predicted value of the image is: 1\n",
      "Actual label of the image is: 1\n",
      "Predicted value of the image is: 0\n",
      "Actual label of the image is: 0\n",
      "Predicted value of the image is: 0\n",
      "Actual label of the image is: 0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dataloader to fetch a batch of images and labels\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    # Move images and labels to the CPU (Pillow works with CPU tensors)\n",
    "    images, labels = images.cpu(), labels.cpu()\n",
    "\n",
    "    # Transform tensor images back to PIL format for display\n",
    "    to_pil = transforms.ToPILImage()\n",
    "\n",
    "    for j in range(min(5, len(images))):  # Limit to 5 images\n",
    "        # Convert tensor to PIL image\n",
    "        pil_image = to_pil(images[j])\n",
    "\n",
    "        # Display image with Pillow\n",
    "        print(f\"Predicted value of the image is: {model(images.to(device)).argmax(1)[j].item()}\")\n",
    "        print(f\"Actual label of the image is: {labels[j].item()}\")\n",
    "\n",
    "        # Display the image using Pillow\n",
    "        pil_image.show()\n",
    "\n",
    "    # Break after processing the first batch (only for demonstration)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "error",
     "timestamp": 1729520682345,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "xbPffDQlZmc9",
    "outputId": "eb470e14-754e-402f-e924-4f412c64dcf0"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Se-h8lDbQqG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPNZXTTGjqRtUQIt/wvpDB5",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
