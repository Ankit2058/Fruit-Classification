{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBju6qwE_w-f"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLRn9m2s_zUu"
   },
   "source": [
    "I have two dataset of rooten and fresh banana  \n",
    "First google drive is mounted to access the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29358,
     "status": "ok",
     "timestamp": 1732322542810,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "R7YEYC1p_7nt",
    "outputId": "e98289da-23b5-470d-ffad-eda404552560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cukcl8DETAi0"
   },
   "source": [
    "I got into this habit of inserting all the imports code in single code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9645,
     "status": "ok",
     "timestamp": 1732322558110,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "0b71uBfBQffE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDB5IZwXdws5"
   },
   "source": [
    "lets get the gpu needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1732322632956,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "7navQiL9dzFF",
    "outputId": "e1623ce7-b7e2-48cc-fd1a-4a2292a82e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_8sjXNrwjY6"
   },
   "source": [
    "Now i save the path to the data in two variables  \n",
    "I will retrive data in the drive via these links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GPU (NVIDIA GeForce GTX 1650)\n",
      "Total GPU Memory: 4.29 GB\n",
      "CUDA Capability: 7.5\n",
      "PyTorch Version: 2.3.1+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert bytes to GB\n",
    "    print(f\"Device: GPU ({gpu_name})\")\n",
    "    print(f\"Total GPU Memory: {total_memory:.2f} GB\")\n",
    "    print(f\"CUDA Capability: {torch.cuda.get_device_properties(0).major}.{torch.cuda.get_device_properties(0).minor}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Device: CPU\")\n",
    "    \n",
    "# PyTorch version\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Selected device\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1732322643825,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "oDwOEmY7uv6J"
   },
   "outputs": [],
   "source": [
    "#Path to folders with data in drive\n",
    "F_Banana = r\"C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\F_Banana\"\n",
    "S_Banana = r\"C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\S_Banana\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TNkAQpOw1d7"
   },
   "source": [
    "This code snippet retrives data from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "executionInfo": {
     "elapsed": 3602,
     "status": "ok",
     "timestamp": 1732322650228,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "79Go3JMcuzra",
    "outputId": "4e9a6ba1-f2cb-43d0-f411-54a7bd15decd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=64x64 at 0x2BDE1D73BD0>\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCyIWaTOMKOfxpjHZl+u7hR71pP8sTqRjI61R8vYQz8k9B6UEopY2ZeXBYjp6VVkIUkmrk+ME1nPk8ntSKIXOSfWq0gNWWHOPSoZmVUJJwPWpKKfmiJyTwKkikZ23vn2HpVSVtzCQjj+EVMdRW2t1SAbppPvsR90elUhM9TuYFjfLf/AKqybraDu7V0d9bSNuJ/hHAqLTdI89/OmAwPuqamc1BXYoRcnY5uPSbq+bKR7Qf71Wx4QfGZJTn0HFdmkYtYh5gQNjnFU5btecYrhniJt9jqjSijj5/Cb7X8uU7gPlBPGaw7rwxqLwqxABHWL3+or0CS+t93M0ecdN4qN5EdeGU/Q0lXmuo3CJ5bc2iWsIW6JW4k6IvRB6msSTdBJuxnafmHqK9L1qyt76ErKgyM7WHVT6iuAuYkWeWFX8xouN394V10avOYTjY981OPa+CMYHIzWVc61Dpe1ZGjjiI/1jNzkdsVseISwsrh4FLT7GKj1OOK8pbRL/UdVjudX8zy5FD7O0Y/u/Wqqwc7JE05cuppax48ErGHTImuZT/Hj5F/xrkr+bWL5x9svXBbkxq2Ao9wOldRfy29jbrBawIsrcRqB+p9qoadpRvLh0kk2RqDLczt/Co6/j2AqY0YxL9o2YdlDBFf2/2hpGh3AsdxyRUWp6rdfbZmgdrdCx2onRR2qxrHlG6drRSkH8AY5IHv71lXLCeEP/y0Xg+4q+WPYV2Murq+kUedeTMrjIAbA/SqlvOY2GOCpp0MokBtnP3uUb0P/wBeqkoZH3chlOCKuMUtES3c+ldSnwzbjz1xXIazqaWtuXPzMx+RB/Ea09b1SKztHuJnwnp3PoBXByyyzytd3I2uw+SPPCL/AI0zNEsSTzyvK4Mlw43Njoq+nsBVWTVJooJ4oXxHMAsgH8WDkV0Ju7TTNHhgs5Vlu7tQ9zJj7i9kH9a4q8X7POwGfLYkp/hSKQSThlIPfkVlzN5UgcfdPapHly+CeGPy/XuKjnAOVPQ/oaLFXKFwAJNyn5T09qmdhcw+d/y0XiQevoaqsSN0TcEGkt5jDLuxkdGHqKpCP//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.jpg\n"
     ]
    }
   ],
   "source": [
    "file_list =os.listdir(F_Banana) #file names in F-Banana are listed in file_list\n",
    "file_name=file_list[0]\n",
    "image_path=os.path.join(F_Banana, file_name)#full path to a particular file\n",
    "image = Image.open(image_path).convert('RGB')  # Converting to RGB\n",
    "image = image.resize((64, 64))#resizing the image\n",
    "print(image)\n",
    "display(image)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5nhOR-KCxo0"
   },
   "source": [
    "So lets give a brief idea of whats been done till now an what things will be done in the future.\n",
    "\n",
    "**Tillnow** we have able to retrive data from the drive link\n",
    "we have a list of links of data which can be later used for training pupose\n",
    "\n",
    "**Whats ahead?**\n",
    "We need to design a dataloader which will load data onto the model\n",
    "We need to make a model\n",
    "Then use the model to predict the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15204,
     "status": "ok",
     "timestamp": 1732322668822,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "Wum-C_yyPRaY",
    "outputId": "fcf562f1-121b-4557-b829-62e8136860c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of images: torch.Size([32, 3, 224, 224])\n",
      "Batch of labels: tensor([1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# Define labels\n",
    "labels = {'fresh': 0, 'rotten': 1}\n",
    "\n",
    "# Load images and assign labels\n",
    "data = []\n",
    "for label, folder in [('fresh', F_Banana), ('rotten', S_Banana)]:\n",
    "    for file_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, file_name)\n",
    "        if file_name.endswith(('.jpg', '.png', '.jpeg')):  # Filter image files\n",
    "            data.append((img_path, labels[label]))\n",
    "\n",
    "# Split into train and test datasets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to a standard size\n",
    "    transforms.ToTensor(),         # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class BananaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BananaDataset(train_data, transform=transform)\n",
    "test_dataset = BananaDataset(test_data, transform=transform)\n",
    "\n",
    "# Convert to DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example: Checking one batch\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch of images: {images.shape}\")  # Should be [batch_size, 3, 224, 224]\n",
    "    print(f\"Batch of labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1732322674186,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "PCb8AxTAE7ff",
    "outputId": "2c95b7c6-8444-404a-caf2-b268566c8a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.BananaDataset object at 0x000002BDE1D9B2D0>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1732322677784,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "3d0m_wHNQzHX",
    "outputId": "272d70fb-6eee-4e14-9c90-1f3823f88e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 480 data for training and 120 for testing\n"
     ]
    }
   ],
   "source": [
    "print(f\"we have {len(train_data)} data for training and {len(test_data)} for testing\")\n",
    "#we have a huge dataset and we cant inset it directly into the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlJW9KZKTc4D"
   },
   "source": [
    "its an matrics of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1732322694129,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "lRn_9gYATV1T"
   },
   "outputs": [],
   "source": [
    "#Working with nn we first need to define or import the model we will be training upon\n",
    "#lets just define it!\n",
    "class neural_network(torch.nn.Module):\n",
    "  #we define the skeleton of our model using class and instante an model as an object, here you will find _init_(constructor) which instanciate every model with attributes flatten and linear_relu_stack that hold the object of the instantiated class\n",
    "  def __init__(self):\n",
    "    super(neural_network,self).__init__()\n",
    "    self.flatten=torch.nn.Flatten() #self.flatten is instanciated from torch.nn.Flatten\n",
    "    #self is used to bring the defined attribute,function out of the  _init_ funtion scope\n",
    "    #Anything defined with \"self\"prefix has its scope across the class\n",
    "    self.linear_relu_stack=torch.nn.Sequential(\n",
    "        nn.Linear(64*64*3,4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1024,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256,2)\n",
    "    )\n",
    "    #Then we defin a forward funtion to propagate input data throught the model\n",
    "  def forward(self,x):\n",
    "     x = self.flatten(x)\n",
    "     logits = self.linear_relu_stack(x)\n",
    "     return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6677,
     "status": "ok",
     "timestamp": 1732322758203,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "Ym9q-Gr_Thl-",
    "outputId": "8d748a68-836f-470a-ff37-be282c7c3987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "# Freeze earlier layers (optional, depending on dataset size)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1732322802952,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "Q8ZRy8jaT1nA"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epoch=10\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1732322928807,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "IlyJkza3VWV6"
   },
   "outputs": [],
   "source": [
    "#so we have build up all of our arsenal required for the final job of training our small model and test how well it did its job\n",
    "#now lets train our model\n",
    "#here we define the tarining_looop which takes dataloader which feeds data in batches, training_loop further takes model itself, loss function and optimizer.\n",
    "#the sole purpose here is to calculate the loss using loss_fn on the ouput of the model when inputed with dataloader input and optimize model parameter using the optimizer specified in the argument\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "      #let us first load the data into the device conatining model\n",
    "        X, y = X.to(device), y.to(device)\n",
    "      #In this loop batch hold the batch value given by dataloader and X and y values yet again from dataloader\n",
    "      #X dosent hold a single image rather it holds batch of images\n",
    "      #We loop through every batch of image\n",
    "      #And perform following computation, every batch\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        #Output of batch of images\n",
    "        loss = loss_fn(pred, y)\n",
    "        #single loss value if computed from the batch of output\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        #we propgate the loss back to each layers for gradient computation\n",
    "        optimizer.step()\n",
    "        #Then we optimize the model parameter\n",
    "        optimizer.zero_grad()\n",
    "        #Everytime we backpropagate, gradients value gets stored for optimization purposes, but if not set to zero the gradient of next batch will be accumulated\n",
    "        #now if you want to optimize the model after every 5 batches of data then do zero-grad after every 5 batches, till then the gradient of each of those 5 batches will be accumulated\n",
    "        #but for now we want to optimize the model after each batch so we need to zero-grad after every batch\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(batch)\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 11177538\n"
     ]
    }
   ],
   "source": [
    "# Calculate total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214626,
     "status": "ok",
     "timestamp": 1732323146444,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "74ftuyUyVo6k",
    "outputId": "0983b843-840a-46bc-8466-fdc64706cdf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.806084  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.507238 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.502695  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.471253 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.416043  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.408723 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.459752  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.358620 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.348041  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.321450 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.321622  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.293445 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.330756  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.269028 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.284358  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.249112 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.199194  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.231901 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.223632  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.216136 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.257987  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.201777 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.238436  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.193100 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.149436  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.182209 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.166728  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.171919 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.143716  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.164134 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.166874  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.157398 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.173383  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.150402 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.124952  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.145101 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.126210  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.139039 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.179670  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.133506 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.125004  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.129755 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.101514  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.123975 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.107932  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.120739 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.110914  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.115658 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.090660  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.112111 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.083482  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.109267 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.124721  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.106740 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.090934  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.103721 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.087687  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.100553 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.095700  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097952 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.091230  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.094939 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.071290  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.093589 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.091578  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.090897 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.088786  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.088071 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.113030  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.087136 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.096052  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.084453 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.056658  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.082900 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.097826  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.080503 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.062660  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.078325 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.118491  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076976 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.063611  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076440 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.076642  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.074853 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.077374  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073539 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.063897  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.071458 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.067971  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.070704 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.090029  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.069929 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.075129  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.068398 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.067538  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066462 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.079288  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065543 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "0\n",
      "loss: 0.124177  [   32/  480]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.064280 \n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "#now all we need to do is train and test the model for the number of times(epochs) we want\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17096,
     "status": "ok",
     "timestamp": 1732323445780,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "kqDIkBePg_8k",
    "outputId": "4263014a-d268-4d23-e625-3caefa5305d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\resnet_model_parameters.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = r\"C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\resnet_model_parameters.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model parameters saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LW1iSHDbbPpA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=150528, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly loading the model parameters if you have already trained the model\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\User\\Desktop\\DeepLearning\\Major Project\\model_parameters.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode (important for inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value of the image is: 0\n",
      "Actual label of the image is: 0\n",
      "Predicted value of the image is: 1\n",
      "Actual label of the image is: 1\n",
      "Predicted value of the image is: 1\n",
      "Actual label of the image is: 1\n",
      "Predicted value of the image is: 0\n",
      "Actual label of the image is: 0\n",
      "Predicted value of the image is: 0\n",
      "Actual label of the image is: 0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dataloader to fetch a batch of images and labels\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    # Move images and labels to the CPU (Pillow works with CPU tensors)\n",
    "    images, labels = images.cpu(), labels.cpu()\n",
    "\n",
    "    # Transform tensor images back to PIL format for display\n",
    "    to_pil = transforms.ToPILImage()\n",
    "\n",
    "    for j in range(min(5, len(images))):  # Limit to 5 images\n",
    "        # Convert tensor to PIL image\n",
    "        pil_image = to_pil(images[j])\n",
    "\n",
    "        # Display image with Pillow\n",
    "        print(f\"Predicted value of the image is: {model(images.to(device)).argmax(1)[j].item()}\")\n",
    "        print(f\"Actual label of the image is: {labels[j].item()}\")\n",
    "\n",
    "        # Display the image using Pillow\n",
    "        pil_image.show()\n",
    "\n",
    "    # Break after processing the first batch (only for demonstration)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "error",
     "timestamp": 1729520682345,
     "user": {
      "displayName": "Ankit Sapkota",
      "userId": "17812249283392455981"
     },
     "user_tz": -345
    },
    "id": "xbPffDQlZmc9",
    "outputId": "eb470e14-754e-402f-e924-4f412c64dcf0"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Se-h8lDbQqG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPNZXTTGjqRtUQIt/wvpDB5",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
